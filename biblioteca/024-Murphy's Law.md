---
type: mental-model
title: "Murphy's Law"
category:
  - pensamento-geral
origin: Edward A. Murphy Jr. (1949)
author_reference: Edward A. Murphy Jr. - Aerospace engineer
domains:
  - probabilidade
  - gestão de risco
  - engenharia
  - planejamento
tags:
  - modelo-mental
  - pensamento
  - probabilidade
  - risco
  - planejamento
  - preparação
aliases:
  - Lei de Murphy
  - Anything That Can Go Wrong Will Go Wrong
created: 2025-01-27
updated: 2025-01-27
---
# [[Murphy's Law]]

> **Teste de Pertinência:** *Você está planejando algo importante e precisa considerar o que pode dar errado para se preparar adequadamente? Se a resposta for "Sim", este modelo é a ferramenta correta para o momento.*

## 1. Definição e Mecanismo
**O que é:**
A Lei de Murphy é um adágio expressando a ideia de que em qualquer situação, se algo *pode* acontecer mal, provavelmente acontecerá - especialmente no pior momento possível. É usado tanto literalmente (ao planejar coisas) quanto humoristicamente (quando algo realmente dá errado).

**Explicação:**
Este modelo funciona porque reconhece que em sistemas complexos com muitas partes móveis, há muitas oportunidades para coisas darem errado. Com probabilidade suficiente e número suficiente de tentativas, coisas que podem dar errado eventualmente darão. Além disso, viés de confirmação faz com que lembremos de vezes que coisas deram errado e esqueçamos quando deram certo.

A lógica central é que antecipar o que pode falhar permite que você se prepare e previna. Em vez de ser pessimismo puro, pode ser uma ferramenta útil para planejamento defensivo e gestão de risco. Projeto líder Lt. Col. John Paul Stapp popularizou a frase dizendo que sua equipe sempre trabalhava com Lei de Murphy em mente - antecipando o que pode falhar para que pudessem prevenir.

Funciona porque:
- **Promove preparação:** Antecipar falhas potenciais permite preparação e prevenção.
- **Reconhece probabilidade:** Com probabilidade suficiente, coisas que podem dar errado eventualmente darão.
- **Alerta para complexidade:** Sistemas complexos têm muitas oportunidades para falhas.
- **Guia design defensivo:** Em engenharia e planejamento, design para falha, antecipe erros, construa redundância.

**Variações relacionadas:**
- **Sod's Law (UK):** Muito similar à Lei de Murphy, às vezes enfatizando que acidentes acontecem *no pior momento possível*.
- **Finagle's Law:** Frequentemente renderizado como "Qualquer coisa que pode dar errado dará - no pior momento possível."
- **Yhprum's Law:** Escrito ao contrário de "Murphy"; tipo de lado otimista: "Qualquer coisa que deveria dar errado não dará."

## 2. Pressupostos Fundamentais
*O modelo só é válido se estas premissas forem verdadeiras:*
* **Pressuposto 1:** Em sistemas complexos, há muitas oportunidades para coisas darem errado.
* **Pressuposto 2:** Com probabilidade suficiente e número suficiente de tentativas, coisas que podem dar errado eventualmente darão.
* **Pressuposto 3:** Antecipar falhas potenciais permite preparação e prevenção.
* **Pressuposto 4:** Viés de confirmação faz com que lembremos de falhas mais do que sucessos.

## 3. Contexto de Aplicação

### Quando Usar (Luz Verde)
* Situações onde o modelo produz boas decisões rapidamente:*
- **Engenharia e projeto:** Ao projetar sistemas, antecipar o que pode falhar e projetar para falha, construir redundância.
- **Planejamento de projetos:** Ao planejar projetos, considerar o que pode dar errado e preparar contingências.
- **Gestão de risco:** Ao gerenciar riscos, antecipar falhas potenciais e desenvolver planos de mitigação.
- **Preparação para eventos:** Ao preparar eventos importantes, considerar o que pode dar errado e preparar backup plans.
- **Tomada de decisão:** Ao tomar decisões importantes, considerar cenários onde coisas podem dar errado.

**Domínios Típicos:** Engenharia, Planejamento de Projetos, Gestão de Risco, Preparação, Tomada de Decisão.

### Quando Evitar (Luz Vermelha)
* Situações onde o modelo induz ao erro ou simplifica demais a realidade:*
- **Paralisia por análise:** Usar o modelo como desculpa para nunca agir porque algo pode dar errado.
- **Pessimismo excessivo:** Focar apenas no que pode dar errado sem considerar probabilidades reais ou preparação adequada.
- **Viés de confirmação:** Lembrar apenas de vezes que coisas deram errado e esquecer quando deram certo.
- **Ignorar probabilidades:** Não todas as coisas que podem dar errado têm mesma probabilidade - algumas são muito improváveis.

## 4. Zona de Risco (Diagnóstico)

### Uso Incorreto Comum
* Como amadores costumam distorcer esse modelo:*
- **Paralisia por análise:** Usar o modelo como desculpa para nunca agir porque algo pode dar errado.
- **Pessimismo excessivo:** Focar apenas no que pode dar errado sem considerar probabilidades ou preparação.
- **Ignorar probabilidades:** Tratar todas as falhas potenciais como igualmente prováveis quando não são.
- **Viés de confirmação:** Lembrar apenas de falhas e esquecer sucessos, criando visão distorcida.
- **Preparação excessiva:** Gastar muito tempo preparando para falhas muito improváveis.

### Sinais de que Você Saiu do Modelo
* **Indicador Comportamental:** 
  - Você está paralisado porque algo pode dar errado.
  - Você está focado apenas no que pode dar errado sem considerar probabilidades.
  - Você está ignorando probabilidades e tratando todas as falhas como igualmente prováveis.
  - Você está gastando muito tempo preparando para falhas muito improváveis.

* **Evidência Prática:** 
  - Você não age porque sempre encontra algo que pode dar errado.
  - Suas preparações são desproporcionais a probabilidades reais de falha.
  - Você tem visão distorcida porque lembra apenas de falhas.
  - Você perde oportunidades porque está muito focado em prevenir falhas improváveis.

## 5. Passos de Pensamento (Algoritmo)
1. **Identifique o que pode dar errado:** Liste coisas que podem dar errado no projeto, sistema ou situação. Seja específico e completo.

2. **Avalie probabilidades:** Para cada falha potencial, avalie probabilidade real. Nem todas as falhas são igualmente prováveis - priorize baseado em probabilidade e impacto.

3. **Avalie impacto:** Para cada falha potencial, avalie impacto se acontecer. Combine probabilidade e impacto para priorizar.

4. **Desenvolva planos de mitigação:** Para falhas de alta probabilidade e alto impacto, desenvolva planos específicos de mitigação ou prevenção.

5. **Construa redundância quando apropriado:** Para sistemas críticos, construa redundância ou backup systems para falhas importantes.

6. **Projete para falha:** Em engenharia e design, projete sistemas que falham de forma segura ou graciosa.

7. **Prepare contingências:** Desenvolva planos de contingência para falhas importantes, mas não gaste tempo excessivo em falhas muito improváveis.

8. **Balance preparação e ação:** Não use o modelo como desculpa para paralisia - prepare adequadamente mas então aja.

9. **Reconheça viés de confirmação:** Lembre-se que você pode lembrar de falhas mais do que sucessos - mantenha perspectiva balanceada.

10. **Monitore e ajuste:** Após implementação, monitore o que realmente dá errado e ajuste preparações accordingly.

## 6. Notas de Campo (Pessoal)
*Reflexões subjetivas, batalhas reais e cicatrizes.*

* **Experiência:** Usei isso ao planejar um projeto importante e o resultado foi antecipar várias falhas potenciais e preparar contingências, resultando em projeto mais robusto que lidou bem com problemas que surgiram.

* **Erro:** Ignorei este modelo ao projetar um sistema e paguei o preço ao não antecipar falhas potenciais, resultando em problemas que poderiam ter sido prevenidos.

* **Insight:** Descobri que Lei de Murphy é especialmente útil quando combinada com avaliação de probabilidades - não é sobre ser pessimista sobre tudo, mas sobre ser realista sobre o que é provável e se preparar accordingly.

* **Aplicação prática:** Usei este modelo para desenvolver planos de contingência para eventos importantes, descobrindo que antecipar o que pode dar errado e preparar backup plans reduz significativamente stress e melhora resultados.

---
## Referências e Conexões
**Modelos Relacionados:**
* [[Risk Management]]
* [[Precautionary Principle]]
* [[Defensive Design]]
* [[Contingency Planning]]
* [[Confirmation Bias]]

**Fontes:**
* Murphy, Edward A. Jr. - Aerospace engineer, origem da frase (1949)
* Stapp, John Paul - Popularização da frase
* Wikipedia - Murphy's Law
* Military.com - History of Murphy's Law

**Exemplos Notáveis:**
* **Projeto MX981 (1949):** Medidores de tensão usados para medir g-forces foram conectados incorretamente; Murphy supostamente disse algo como: "Se há alguma forma de fazer errado, ele fará."
* **Engenharia:** Usado como aviso para projetar para falha, antecipar erros, construir redundância.
